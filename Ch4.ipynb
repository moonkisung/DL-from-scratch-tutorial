{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJhi/TFdqCcJMuKk9QsG4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonkisung/DL-from-scratch-tutorial/blob/main/Ch4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-nifEaa8jUr"
      },
      "source": [
        "\n",
        "# 4.1 Learning in Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxLw4QCH8jS5"
      },
      "source": [
        "## 4.1.1 Data-driven Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNNCVfCQ8jQ0"
      },
      "source": [
        "## 4.1.2 Train Data and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VcKkUVt_j0t"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EovukWgN8jOi"
      },
      "source": [
        "# 4.2 Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zaQvYpW-1Sj"
      },
      "source": [
        "## 4.2.1 Sum of Squares for Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdcIBXnC_CEU"
      },
      "source": [
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv-3lqw-_TWR"
      },
      "source": [
        "def sum_squares_error(y, t):\n",
        "    return 0.5 * np.sum((y-t)**2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMcWGfPF_fud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a375e58c-a32a-4500-b9b4-1c8d67a58571"
      },
      "source": [
        "sum_squares_error(np.array(y), np.array(t))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09750000000000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMKilcnb_0Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9532f9b-54ea-44cb-acee-5052fd849c72"
      },
      "source": [
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "sum_squares_error(np.array(y), np.array(t))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk_TaIzd-1Wu"
      },
      "source": [
        "## 4.2.2 Cross Entropy Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdrrFPuBCuvr"
      },
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    delta = 1e-7\n",
        "    return -np.sum(t * np.log(y + delta))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI37WLUvCrBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0911e95e-2198-45ad-c4d8-32fc49ee97fc"
      },
      "source": [
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.510825457099338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52v9ggviDIKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bfb114a-b983-4dfb-a354-4b21dd905d56"
      },
      "source": [
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.302584092994546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2KXeMmk-1Zw"
      },
      "source": [
        "## 4.2.3 Minibatch Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJrJoc31Gssj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c90c39-652e-4fd0-a901-977d7cd21d39"
      },
      "source": [
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 826, done.\u001b[K\n",
            "remote: Total 826 (delta 0), reused 0 (delta 0), pack-reused 826\u001b[K\n",
            "Receiving objects: 100% (826/826), 52.21 MiB | 36.82 MiB/s, done.\n",
            "Resolving deltas: 100% (477/477), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCF2hRTtHOST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a70318-4e3c-46f3-f7f9-194157c643a1"
      },
      "source": [
        "%cd /content/deep-learning-from-scratch/ch04"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning-from-scratch/ch04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UuNslMKDiNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59662217-ac47-4039-c0f5-97c25bafd872"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n",
            "(60000, 784)\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA_UYemmG1zh"
      },
      "source": [
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ute97X_E1rhP"
      },
      "source": [
        "## 4.2.4 (For Batch)Implementing Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaP7LGkiHRGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6afb1bab-e1bc-4200-9cf4-529033c4b3d5"
      },
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
        "\n",
        "y = np.array([0.1,0.5,0.7])\n",
        "t = np.array([0,0,1])\n",
        "cross_entropy_error(y, t)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3566748010815999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RnOFb5voIzr"
      },
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "    \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUGVm-VX2Aag"
      },
      "source": [
        "##4.2.5 Why set up Loss Function?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FVpCMKg2TuR"
      },
      "source": [
        "# 4.3 Numerical Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHhJU5od2dj3"
      },
      "source": [
        "## 4.3.1 Differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIntmrnz0j0s"
      },
      "source": [
        "def numerical_diff(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    return (f(x+h)-f(x-h)) / (2*h)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqVWFTK92khb"
      },
      "source": [
        "## 4.3.2 Examples of Numerical Differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_uPeDhW1bGY"
      },
      "source": [
        "def function_1(x):\n",
        "    return 0.01*x**2 + 0.1*x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHzJADGl1j99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "905dc69d-68a7-4e14-a71d-61286c198217"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "x = np.arange(0, 20.0, 0.1)  # 20은 미포함\n",
        "y = function_1(x)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sigzfddICujH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66b3069-1233-4d4b-eb95-de3666746c21"
      },
      "source": [
        "numerical_diff(function_1, 5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1999999999990898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhPUCF0_C8RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea90e24-a7d4-4160-bed2-7e24c821fbb0"
      },
      "source": [
        "numerical_diff(function_1, 10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2999999999986347"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJjyitkUDIMi"
      },
      "source": [
        "## 4.3.3 Partial derivative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "514tamC2C-VX"
      },
      "source": [
        "def function_2(x):\n",
        "    return x[0]**2 + x[1]**2\n",
        "    return np.sum(x**2)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0ffBk34Dwac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32ae526-65cc-418c-feab-dae1823e299c"
      },
      "source": [
        "# Problem 1: When x0 = 3, x1 = 4, Calculate partial derivative about x0\n",
        "def function_tmp1(x0):\n",
        "    return x0*x0 + 4.0**2.0\n",
        "\n",
        "numerical_diff(function_tmp1, 3.0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.00000000000378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuqOvY_PGdD0"
      },
      "source": [
        "# Problem 2: When x0 = 3, x1 = 4, Calculate partial derivative about x1\n",
        "def function_tmp2(x1):\n",
        "    return 3.0**2.0 + x1*x1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8wRzxL5GrOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873bb08d-7fcb-4407-ba42-390c9409c01a"
      },
      "source": [
        "numerical_diff(function_tmp2, 4.0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.999999999999119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUcPayBFHFIY"
      },
      "source": [
        "# 4.4 Gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viGImOYSHCz5"
      },
      "source": [
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4\n",
        "    grad = np.zeros_like(x)  # x와 형상이 같은 배열을 생성\n",
        "    \n",
        "    for idx in range(x.size):\n",
        "        tmp_val = x[idx]\n",
        "        # Calculating f(x+h)\n",
        "        x[idx] = tmp_val + h\n",
        "        fxh1 = f(x)\n",
        "        # print(fxh1)\n",
        "        # Calculation f(x-h)\n",
        "        x[idx] = tmp_val - h\n",
        "        fxh2 = f(x)\n",
        "\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        x[idx] = tmp_val  # restoring values\n",
        "\n",
        "    return grad"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ipdyelLJGBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab47c18-57b6-49ce-934d-4e1b9f4c0ce4"
      },
      "source": [
        "np.array([2,4]).size"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TWLm-w6MiZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3e6651-a616-49af-b714-d24d09011b9b"
      },
      "source": [
        "np.zeros_like(np.array([2,4]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxydAenBBT9Z"
      },
      "source": [
        "# def function_2(x):\n",
        "#     return x[0]**2 + x[1]**2\n",
        "#     return np.sum(x**2)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjEacc-KJJIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10f86598-8335-406d-b541-36d270203286"
      },
      "source": [
        "numerical_gradient(function_2, np.array([3.0, 4.0]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6., 8.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgtiZhlIMEnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec7919a-322a-4082-992b-82c4d6b90a49"
      },
      "source": [
        "numerical_gradient(function_2, np.array([0.0, 2.0]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHSfAfUxMIXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840f9a9b-0e36-4ca8-b83c-c6732e72e0ea"
      },
      "source": [
        "numerical_gradient(function_2, np.array([3.0, 0.0]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOT7ZUkTRd84"
      },
      "source": [
        "## 4.4.1 Gradient method(Gradient Descent Method)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO6DGDXxMJ2F"
      },
      "source": [
        "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
        "    x = init_x\n",
        "\n",
        "    for i in range(step_num):\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x -= lr * grad\n",
        "    return x"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae_4qRUdS3wH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6055444-aec4-4852-8b67-76c01b1e1db8"
      },
      "source": [
        "# Problem : Calculating minimum values using gradient method\n",
        "def function_2(x):\n",
        "    return x[0]**2 + x[1]**2\n",
        "\n",
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.11110793e-10,  8.14814391e-10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdtYRuh_TWfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4663aee-20d9-48dc-d80b-755d71bcc6a9"
      },
      "source": [
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.58983747e+13, -1.29524862e+12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv5vpStkTZDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87b1aa3-cd36-4efc-d14d-08f3c74a80aa"
      },
      "source": [
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.99999994,  3.99999992])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7jK93LYUnA_"
      },
      "source": [
        "## 4.4.2 Gradient in Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZpGJZvvUOZQ"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
        "import numpy as np\n",
        "from common.functions import softmax, cross_entropy_error\n",
        "from common.gradient import numerical_gradient"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MhK6AapW8ER"
      },
      "source": [
        "class simpleNet:\n",
        "    def __init__(self):\n",
        "        self.W = np.random.randn(2,3) # initializing normal distribution\n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.dot(x, self.W)\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        z = self.predict(x)\n",
        "        y = softmax(z)\n",
        "        loss = cross_entropy_error(y, t)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz2PcC9QX3Ru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90c3a95-35b5-4e62-f029-2e486b28a0f9"
      },
      "source": [
        "net = simpleNet()\n",
        "print(net.W)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.65602462  0.83133543 -0.71086548]\n",
            " [ 0.977846    0.61654707  0.30627754]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wx3PBMBX6P4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1079d6da-7a8f-411b-c77e-cdec17cde095"
      },
      "source": [
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)\n",
        "print(p)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.27367617  1.05369362 -0.15086951]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn3Ta72OYHdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2446379f-0b51-4ddb-9f5b-56c7ce9fa714"
      },
      "source": [
        "np.argmax(p)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNKgjSxEaGUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd1bd8d-da7d-4d55-e4b4-0c8a5fc026bc"
      },
      "source": [
        "softmax(p)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.48944019, 0.39279181, 0.117768  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R50R79SDYRoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4dc590a-e327-4b17-de42-aea9692597e1"
      },
      "source": [
        "t = np.array([0, 0, 1])\n",
        "net.loss(x, t)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.139037834538429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te-bt87oYcEs"
      },
      "source": [
        "def f(W):\n",
        "    return net.loss(x, t)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubCa1yQ286Au"
      },
      "source": [
        "f = lambda w: net.loss(x, t)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWFTmjVW499P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6de33f-bc74-4217-d9e9-0d31c0066370"
      },
      "source": [
        "dW = numerical_gradient(f, net.W)\n",
        "print(dW)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.29366387  0.23567488 -0.52933875]\n",
            " [ 0.4404958   0.35351233 -0.79400812]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61BawhT5_7HR"
      },
      "source": [
        "# 4.5 Implement Learning Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOar16cyAftv"
      },
      "source": [
        "## 4.5.1 Implement Two layer Neural Network Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSzCbbbQ5AuG"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "from common.functions import *\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "class TwoLayerNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "        # Initializing Weights\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    def predict(self, x):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = sigmoid(z1)\n",
        "\n",
        "        return y\n",
        "    \n",
        "    # x : input data, t : true label\n",
        "    def loss(x, t):\n",
        "        y = self.predict(x)\n",
        "        \n",
        "        return cross_entropy_error(y, t)\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        t = np.argmax(t, axis=1)\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "\n",
        "        return grads"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf-8bWXnDqKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b751cf52-dd26-492b-9825-fb002b4242be"
      },
      "source": [
        "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
        "print(net.params['W1'].shape)\n",
        "print(net.params['b1'].shape)\n",
        "print(net.params['W2'].shape)\n",
        "print(net.params['b2'].shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UUj7YY0Dsa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7dee37-98b4-4f3b-b048-c5227b1576b2"
      },
      "source": [
        "x = np.random.rand(100, 784)\n",
        "y = net.predict(x)\n",
        "print(y)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.61856961 0.61709703 0.62815774 ... 0.6183943  0.62964834 0.61257952]\n",
            " [0.60753324 0.61645418 0.62367291 ... 0.62315102 0.62923447 0.60656029]\n",
            " [0.61143406 0.6124368  0.62816545 ... 0.61522334 0.63151617 0.60784339]\n",
            " ...\n",
            " [0.60816273 0.61428203 0.63094415 ... 0.62629401 0.63131501 0.60863075]\n",
            " [0.61811084 0.61058916 0.62270258 ... 0.63021305 0.62760034 0.61197988]\n",
            " [0.61547522 0.61567039 0.62247645 ... 0.62127281 0.63022683 0.61788625]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7UAgTxwCoV8"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGlC9jEHhaCo"
      },
      "source": [
        "## 4.5.2 Implement Mini-batch Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdSSfkLqFi78"
      },
      "source": [
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "train_loss_list = []\n",
        "\n",
        "# Hyperparameter\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100  # Minibatch Size\n",
        "learning_rate = 0.1\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    # Obtaining Mini-batch\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    # Calculating gradient\n",
        "    grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    # grad = network.gradient(x_batch, t_batch) # Performance improvement version\n",
        "\n",
        "    # Hyperparameter update\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    # Recording Learning Process\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAHJPGWee9bj"
      },
      "source": [
        "## 4.5.3 Validation using test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz7OzPLdnJIw"
      },
      "source": [
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "# Hyperparameter\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100  # Minibatch Size\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    # Obtaining Mini-batch\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    # Calculating gradient\n",
        "    grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    # grad = network.gradient(x_batch, t_batch) # Performance improvement version\n",
        "\n",
        "    # Hyperparameter update\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    # Recording Learning Process\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    # Calculating accuracy per 1epoch\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(\"train acc, test acc : \"\n",
        "            + str(train_acc) + \", \" = str(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3wtR_wFfEYe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}